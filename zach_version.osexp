---
API: 2.1
OpenSesame: 3.3.14
Platform: nt
---
set width 1920
set uniform_coordinates yes
set title "New experiment"
set subject_parity even
set subject_nr 0
set start experiment
set sound_sample_size -16
set sound_freq 48000
set sound_channels 2
set sound_buf_size 1024
set sampler_backend legacy
set round_decimals 2
set psychopy_monitor testMonitor
set mouse_backend psycho
set keyboard_backend psycho
set height 1080
set fullscreen no
set form_clicks no
set foreground white
set font_underline no
set font_size 18
set font_italic no
set font_family mono
set font_bold no
set experiment_path "C:/Users/RA-Eyelink/Salience_Priority"
set disable_garbage_collection yes
set description "The main experiment item"
set coordinates uniform
set compensation 0
set color_backend psycho
set clock_backend psycho
set canvas_backend psycho
set background "#2b2b2b"

define inline_script constants
	set description "Executes Python code"
	___run__
	"""
	Define some experimental constants.
	If running on local machine, change second cwd to the desired folder and then comment out the first cwd
	"""
	import pygaze
	
	debug = False
	exp_num = 2
	cwd =  "C:\\Users\\RA-Eyelink\\Salience_Priority"
	# cwd = '/Users/zach/RA_2023/Salience_Priority/experiment'
	results = []
	to_target_list = []
	RTs = []
	
	TRACKER_ON = False #type(eyetracker) != pygaze._eyetracker.libdummytracker.Dummy
	__end__
	set _prepare ""

define sequence experiment
	set flush_keyboard yes
	set description "Runs a number of items in sequence"
	run new_pygaze_init always
	run constants always
	run utils always
	run singleton_session always
	run singleton_trial always
	run new_form_text_input always
	run new_form_text_input_1 always
	run main always

define inline_script main
	set description "Executes Python code"
	___run__
	"""
	File to read in settings file, initialize Session and run it.
	"""
	
	from psychopy import visual, core, event, gui
	from psychopy.tools.monitorunittools import deg2pix
	import random
	import numpy as np
	
	import sys
	import os
	import os.path as op
	
	import yaml
	
	
	def main():
	    
	    log.write(f"age, {var.age}")
	    log.write(f"gender, {var.gender}")
	    with open(op.join(cwd, 'experiment_settings.yml'), 'r') as f_in:
	        params = yaml.safe_load(f_in)
	        
	    sj_num = self.get('subject_nr') # subject number
	    
	    
	    print(f"Running experiment {exp_num} for subject {sj_num}")
	    
	    # make output dir
	    if params['paths']['curr_dir'] == 'lab':
	        output_dir = op.join(params['paths']['data_pth']['lab'], 'sub-{sj}'.format(sj=sj_num))
	    else:
	        base_dir = op.split(cwd)[0]  # main path for all folders of project
	        output_dir = op.join(base_dir, 'output', 'sourcedata', 'sub-{sj}'.format(sj=sj_num))
	    
	    # if output path doesn't exist, create it
	    if not op.isdir(output_dir):
	        os.makedirs(output_dir)
	    print('saving files in %s' % output_dir)
	    
	    # if file already exists
	    output_str = str(sj_num)
	    behav_file = op.join(output_dir, f"behavioral_data_mieke{sj_num}.pickle")
	    
	    if op.exists(behav_file):
	        print('file already exists!')
	        
	    exp_sess = SingletonSession(output_str=output_str,
	                                output_dir=output_dir,
	                                eyetracker_on=True,
	                                settings=params,
	                                behav_file=behav_file,
	                                subject_number=sj_num,
	                                exp_num=exp_num,
	                                debug=debug)
	    
	    exp_sess.run()
	
	
	main()
	__end__
	set _prepare ""

define form_text_input new_form_text_input
	set timeout infinite
	set spacing 10
	set rows "1;1;6"
	set only_render no
	set margins "50;50;50;50"
	set form_var age
	set form_title Age
	set form_question "Please enter your age"
	set description "A simple text input form"
	set cols 1
	set _theme gray
	widget 0 0 1 1 label text="[form_title]"
	widget 0 1 1 1 label center=no text="[form_question]"
	widget 0 2 1 1 text_input focus=yes return_accepts=yes stub="" var="[form_var]"


define form_text_input new_form_text_input_1
	set timeout infinite
	set spacing 10
	set rows "1;1;6"
	set only_render no
	set margins "50;50;50;50"
	set form_var gender
	set form_title Gender
	set form_question "Please enter your gender (Male, Female, Other)"
	set description "A simple text input form"
	set cols 1
	set _theme gray
	widget 0 0 1 1 label text="[form_title]"
	widget 0 1 1 1 label center=no text="[form_question]"
	widget 0 2 1 1 text_input focus=yes return_accepts=yes stub="" var="[form_var]"


define pygaze_init new_pygaze_init
	set tracker_type "Advanced dummy (mouse simulation)"
	set tobiiglasses_udpport 49152
	set tobiiglasses_address "192.168.71.50"
	set smi_send_port 4444
	set smi_recv_port 5555
	set smi_ip "127.0.0.1"
	set sacc_vel_thr 35
	set sacc_acc_thr 9500
	set eyelink_pupil_size_mode area
	set eyelink_force_drift_correct yes
	set description "Initialize and calibrate eye tracker"
	set calibrate yes
	set calbeep no
	set alea_api_key "Contact Alea for an API key"
	set alea_animated_calibration no
	set _logfile automatic

define inline_script singleton_session
	set description "Executes Python code"
	___run__
	"""
	This file defines a Session Object
	The Session object contains a list of trials and practice trials
	which are constructed in the create_trials() method. 
	
	The run() method can be called to initialize and run the experiment.
	"""
	
	
	from typing import List, Tuple
	import os 
	
	import numpy as np
	from copy import deepcopy
	from psychopy import visual
	from psychopy import prefs
	from psychopy import sound
	from functools import partial
	
	from psychopy.tools.monitorunittools import deg2pix
	
	Coordinate = Tuple[int, int]
	
	
	class SingletonSession():
	    def __init__(self, output_str, output_dir, settings, behav_file, eyetracker_on, subject_number, exp_num, debug):
	        
	
	
	
	        self.results = []
	        self.practice_trials = []
	        self.trials = []
	        self.trial_parameters = {"subject_number": subject_number} # A dictionary containing global trial parameters
	        self.to_target_list = []
	        self.exp_num = exp_num
	        self.debug = debug
	        self.screen = np.array([win.size[0], win.size[1]])
	        self.settings = settings
	
	        self.exp_str = f"exp{self.exp_num}"
	        self.num_reps = self.settings["study"][self.exp_str]["num_reps"]
	        self.bg_orientations = self.settings["stimuli"]["bg_orientation"]
	        self.SOAs = self.settings["study"][self.exp_str]["SOAs"]
	        self.num_blocks = self.settings["study"][self.exp_str]["num_blocks"]
	        self.behav_file = behav_file
	
	        # print(self.trial_parameters["target_orientation"], self.trial_parameters["distractor_orientation"])
	        
	        # Counterbalancing here
	        if subject_number % 2 == 0:
	            self.trial_parameters["target_orientation"] = self.settings["stimuli"]["singleton_orientation"][0]
	            self.trial_parameters["distractor_orientation"] = self.settings["stimuli"]["singleton_orientation"][1]
	
	        else:
	            self.trial_parameters["target_orientation"] = self.settings["stimuli"]["singleton_orientation"][1]
	            self.trial_parameters["distractor_orientation"] = self.settings["stimuli"]["singleton_orientation"][0]
	
	
	        self.trial_parameters["window_size"] = self.settings["window_extra"]["size"]
	        self.trial_parameters["practice_trials"] = self.settings["study"][f"exp{self.exp_num}"]["practice_trials"]
	        self.trial_parameters["ITI_wait"] = self.settings["trial_info"]["ITI_wait"]
	        self.trial_parameters["singleton_area"] = self.settings["stimuli"]["singleton_area"]
	
	        self.instructions = {
	            "target_direction": "left" if self.trial_parameters["target_orientation"] < 0 else "right",
	            "target_symbol": "\\" if self.trial_parameters["target_orientation"] < 0 else "/",
	            "distractor_direction": "left" if self.trial_parameters["distractor_orientation"] < 0 else "right",
	            "distractor_symbol": "\\" if self.trial_parameters["distractor_orientation"] < 0 else "/",
	        }
	
	        self.max_dist = self.settings["stimuli"]["fix_check_rad"]
	
	        self.trial_parameters["max_dist"] = self.max_dist
	        print("MAX_DIST", self.max_dist)
	        
	        self.trial_parameters["fixation_diameter"] = deg2pix(settings["stimuli"]["fixation_diameter"], win.monitor)
	        
	        # eyetracker.set_draw_drift_correction_target_func(partial(draw_fixation, screen=win, color=pygaze.settings.FGC,     pw=1, diameter=self.trial_parameters["fixation_diameter"]))
	        
	
	        ########################
	
	    def run(self):
	        """
	        First create all the trials so we don't have to wait for that
	        Then show the instructions
	        Then execute practice trials
	        Then execute actual trials
	        """
	        
	        RTs = []
	        correct = []
	        self.create_trials()
	        print(len(self.trials))
	        
	        print("NUM TRIALS", len(self.trials))
	        
	
	
	        # draw instructions wait a few seconds
	        this_instruction_string = (f"Instructions"
	                                   f"\n\nThe task is to move your eyes to a line that is rotated to the "
	                                   f"{self.instructions['target_direction']} ({self.instructions['target_symbol']})."
	                                   f"\nTry not to make eye movements to the distractor line that is rotated to the "
	                                   f"{self.instructions['distractor_direction']} "
	                                   f"({self.instructions['distractor_symbol']})."
	                                   f"\n Before each trial, press the -spacebar- to start"
	                                   f"\n\n Press the -spacebar- to continue.")
	
	        draw_instructions(win, this_instruction_string, keys='space')
	
	        this_instruction_string = (f"\nTry to be as fast and accurate as possible!"
	                                   f"\nMove as soon as you see the target (which is also when the fixation dot in the "
	                                   f"middle disappears)"
	                                   f"\n\n\nPlease press the -spacebar- to continue")
	
	        draw_instructions(win, this_instruction_string, keys='space')
	
	        this_instruction_string = (f"You will now start with a practice session."
	                                   f"\n\nYou will get a warning if you select the distractor instead of the target"
	                                   f"\nYou will also get a warning if you make more than one eye movement to reach the "
	                                   f"target"
	                                   f"\n\nPlease press the -spacebar- to begin.")
	
	        draw_instructions(win, this_instruction_string, keys='space')
	
	        if not self.debug:
	            for trial in self.practice_trials:
	                end_of_block, RTs, correct = trial.run(RTs, correct)
	                if end_of_block:
	                    RTs = []
	                    correct = []
	
	
	        # if self.eyetracker_on:
	        #     eyetracker.start_recording()
	        
	
	    
	        for trial in self.trials:
	            end_of_block, RTs, correct = trial.run(RTs, correct)
	            if end_of_block:
	                RTs = []
	                correct = []
	        
	
	
	    def create_trials(self):
	        
	        # Construct coordinates
	        pixel_l = deg2pix(self.settings["stimuli"]["line_length"], win.monitor)
	        pixel_w = deg2pix(self.settings["stimuli"]["line_width"], win.monitor)
	        pixel_spacing = deg2pix(self.settings["stimuli"]["spacing"], win.monitor) + np.max([pixel_l, pixel_w])
	        coordinates = grid_coordinates(self.settings["stimuli"]["x_count"],
	                                       self.settings["stimuli"]["y_count"],
	                                       pixel_spacing)
	        
	        print("PIXEL_SPACING", pixel_spacing)
	
	        # To save memory, we construct all the possible objects and then address them so we can access 
	        # them when constructing our trial objects
	        
	        # Returns a list of tuples of Coordinates where the first tuple is the target and the second the distractor
	        possible_singleton_locations = construct_singleton_pairs(pixel_spacing,
	                                                                 self.settings["stimuli"]["x_count"],
	                                                                 self.settings["stimuli"]["y_count"])
	
	        possible_grids = dict()
	        possible_singletons = dict()
	
	        # We want to randomize presentation of:
	        # Background orientation, Singleton Location
	        for bg_orientation in self.bg_orientations:
	            for target_coord, distractor_coord in possible_singleton_locations:
	                grid_coords = [coordinate for coordinate in coordinates
	                               if coordinate != target_coord and coordinate != distractor_coord]
	                key = f"{bg_orientation}{target_coord}{distractor_coord}"
	
	                possible_grids[key] = visual.ElementArrayStim(win,
	                                                              nElements=len(grid_coords),
	                                                              xys=grid_coords,
	                                                              oris=bg_orientation,
	                                                              units='pix',
	                                                              autoLog=False,
	                                                              sizes=(pixel_w, pixel_l),
	                                                              elementMask=None,
	                                                              elementTex=None,
	                                                              interpolate=False)
	                possible_singletons[key] = visual.ElementArrayStim(win,
	                                                                   nElements=2,
	                                                                   xys=[target_coord, distractor_coord],
	                                                                   oris=[self.trial_parameters["target_orientation"],
	                                                                         self.trial_parameters[
	                                                                             "distractor_orientation"]],
	                                                                   units='pix',
	                                                                   autoLog=False,
	                                                                   sizes=(pixel_w, pixel_l),
	                                                                   elementMask=None,
	                                                                   elementTex=None)
	
	
	        # To randomize trials but ensure blocks happen at the correct trial number,
	        # We cannot construct our trials and then shuffle them since we want to set end_of_block now
	        # So we create a list of trial numbers which we first shuffle.
	        # Then as we can iterate over this list and assign a constructed trial with the now shuffled number.
	        # We append them to our trial list and then sort on trial number. The numbers will be sorted but the 
	        # contents of the trials will be random
	        
	
	        num_trials = (self.num_reps *
	                      len(self.bg_orientations) *
	                      len(self.SOAs) *
	                      len(possible_singleton_locations))
	
	        if num_trials % self.num_blocks != 0:
	            raise RuntimeError(f"{self.num_blocks} blocks won't divide {num_trials} trials evenly. Change experiment settings.")
	            self.close()
	
	        trials_per_block = num_trials // self.num_blocks
	        self.trial_parameters["num_blocks"] = self.num_blocks
	
	        trial_indices = np.arange(num_trials)
	        np.random.shuffle(trial_indices)  # Randomise trials
	        trial_i = 0
	        
	        # We do the same with practice trials then take the first N from that list. This ensures the practice trials
	        # bear no relation with the actual trials since they are shuffled separately
	        practice_trial_indices = np.arange(num_trials)
	        np.random.shuffle(practice_trial_indices)
	        
	        half_frame = int((1000/3) / self.settings["monitor"]["framerate"])  # 1/3 frame in ms
	
	        for rep in range(self.num_reps):
	            for target_coord, distractor_coord in possible_singleton_locations:
	                for bg_orientation in self.bg_orientations:
	                    for SOA in self.SOAs:
	                    
	
	                        trial_num = trial_indices[trial_i]
	                        block_num = (trial_num // trials_per_block) + 1
	
	                        key = f"{bg_orientation}{target_coord}{distractor_coord}"
	
	                        _trial_parameters = deepcopy(self.trial_parameters)
	
	                        # target salient or  not
	                        if abs(self.trial_parameters["target_orientation"] - bg_orientation) > \
	                                abs(self.trial_parameters["distractor_orientation"] - bg_orientation):
	                            _trial_parameters["target_salience"] = "high"
	                        else:
	                            _trial_parameters["target_salience"] = "low"
	
	                        _trial_parameters["target_pos"] = target_coord
	                        _trial_parameters["distractor_pos"] = distractor_coord
	                        _trial_parameters["bg_orientation"] = bg_orientation
	                        _trial_parameters["SOA"] = SOA
	
	                        _trial_parameters["practice"] = False
	
	                        grid = possible_grids[key]
	                        singletons = possible_singletons[key]
	
	                        initialization_time = self.settings["trial_info"]["initialization_time"] 
	
	                        if SOA < 0:
	                            stimulus1 = grid
	                            _trial_parameters["stimulus1_log"] = "stimuli_show"
	                            stimulus2 = singletons
	                            _trial_parameters["stimulus2_log"] = "target_display"
	                            initialization_time += SOA # Adding a negative SOA will decrease time to ensure singletons presented after same duration
	                        else:
	                            stimulus1 = singletons
	                            _trial_parameters["stimulus1_log"] = "target_display"
	                            stimulus2 = grid
	                            _trial_parameters["stimulus2_log"] = "stimuli_show"
	
	                        # Construct phases but subtract half a frame since timing is always rounded up to nearest frame
	                        # See https://osdoc.cogsci.nl/3.2/manual/timing/
	                        jitter = self.settings["trial_info"]["jitter"]
	                        phases = {
	                            "initialization": initialization_time - half_frame,
	                            "stimulus1": np.abs(SOA) - half_frame,
	                            "stimulus2": self.settings["trial_info"]["max_response_time"] - half_frame,
	                            "ITI": self.settings["trial_info"]["ITI"] \
	                                    + np.random.uniform(-jitter, jitter) \
	                                    - self.trial_parameters["ITI_wait"]
	                                    - half_frame,
	                        }
	                        
	                        trial = SingletonTrial(trial_nr=trial_num,
	                                                          block_num=block_num,
	                                                          phases=phases,
	                                                          parameters=_trial_parameters,
	                                                          stimulus1=stimulus1,
	                                                          stimulus2=stimulus2,
	                                                          debug=self.debug,
	                                                          behavioural_file=self.behav_file)
	
	                        if (trial_num + 1) % trials_per_block == 0:
	                            trial.phases["end_of_block"] = 1000
	
	                        self.trials.append(trial)
	                        
	                        
	                        practice_trial_num = practice_trial_indices[trial_i]
	                        practice_trial = SingletonTrial(trial_nr=practice_trial_num,
	                                                          block_num=0,
	                                                          phases=phases,
	                                                          parameters=_trial_parameters,
	                                                          stimulus1=stimulus1,
	                                                          stimulus2=stimulus2,
	                                                          debug=self.debug,
	                                                          behavioural_file=self.behav_file)
	                        
	                        if practice_trial_num == self.settings["study"][self.exp_str]["practice_trials"] - 1:
	                            practice_trial.phases["end_of_block"] = 1000
	                            
	                        practice_trial.parameters["practice"] = True
	                        self.practice_trials.append(practice_trial)
	                        
	                        trial_i += 1
	                            
	
	
	        self.trials = sorted(self.trials, key=lambda trial: trial.trial_nr)
	        
	        self.practice_trials = sorted(self.practice_trials, key=lambda trial: trial.trial_nr)
	        self.practice_trials = self.practice_trials[:self.settings["study"][self.exp_str]["practice_trials"]]
	
	        # print("TRIALS")
	        # for trial in self.trials:
	        #     print(trial.trial_nr, trial.block_num, "end_of_block" in trial.phases.keys(), trial.SOA)
	
	        # print("PRACTICE TRIALS")
	        # for trial in self.practice_trials:
	        #     print(trial.trial_nr, trial.block_num, "end_of_block" in trial.phases.keys(), trial.SOA, trial.bg_orientation)
	__end__
	set _prepare ""

define inline_script singleton_trial
	set description "Executes Python code"
	___run__
	"""
	This file defines a Trial object
	
	The Trial object contains information about how the trial should run and what should be presented.
	It is initialised with a dictionary of phases each with a specified time.
	
	The phases (which are defined functions) are executed in the run() method
	
	"""
	
	import numpy as np
	
	# import pylink
	from typing import Dict, List, Optional, Tuple
	
	import pickle
	# import psychtoolbox as ptb
	from psychopy.visual.elementarray import ElementArrayStim
	from psychopy.visual.circle import Circle
	from psychopy import event, visual
	from psychopy import sound
	from openexp.synth import synth
	my_synth = synth(self.experiment, osc = "sine", freq = 500, attack = 0, length = 100)
	
	class SingletonTrial():
	    def __init__(self,
	                 trial_nr: int,
	                 block_num: int,
	                 phases: Dict[str, float],
	                 parameters: Dict,
	                 stimulus1: ElementArrayStim,
	                 stimulus2: ElementArrayStim,
	                 behavioural_file: str,
	                 debug: bool):
	
	
	        self.RT = None
	        self.success = None
	        self.endpos = None
	        self.startpos = None
	        self.endtime = None
	        self.t0 = None
	        self.response = None
	        self.target_pos = parameters['target_pos']
	        self.distractor_pos = parameters['distractor_pos']
	        self.SOA = parameters['SOA']
	        self.bg_orientation = parameters['bg_orientation']
	        self.target_orientation = parameters["target_orientation"]
	        self.distractor_orientation = parameters["distractor_orientation"]
	        
	
	        self.stimulus1 = stimulus1
	        self.stimulus2 = stimulus2
	
	        self.trial_nr = trial_nr
	        self.block_num = block_num
	
	        self.parameters = dict(parameters)
	
	        self.behavioural_file = behavioural_file
	        self.debug = debug
	        self.phases = dict(phases)
	        
	        
	    def run(self, RTs, correct):
	        self.RTs = RTs
	        # print("RTs", self.RTs)
	        # print("CORRECT", correct)
	        # print("BLOCK_INFO", self.block_num, self.parameters["num_blocks"])
	        self.correct = correct
	        
	        # print("practice", self.parameters["practice"])
	        
	        # Initialize the trial 
	        self.initialization()
	        
	        # Check if still fixating. If not, restart the trial
	        for ms in clock.loop_for(self.phases["initialization"]):
	            if not self.fix_check():
	                self.ITI()
	                clock.sleep(self.phases["ITI"])
	                return False, self.RTs, self.correct
	        
	        if self.SOA != 0:
	            # Draw stimulus 1, could be targets are background depending on SOA
	            self.draw_stim1()
	            
	        
	            # If the targets are being displayed second, we still need to check fixation is being maintained
	            for ms in clock.loop_for(self.phases["stimulus1"]):
	                if self.parameters["stimulus2_log"] == "target_display":
	                    if not self.fix_check():
	                        self.ITI()
	                        clock.sleep(self.phases["ITI"])
	                        return False, self.RTs, self.correct
	            
	        
	       
	        # Draw stimulus 2, may be singletons or background depending on SOA
	        self.draw_stim2()
	        
	        
	        clock.sleep(self.parameters["ITI_wait"])  # Wait before removing grid, otherwise too fast
	
	        # Run ITI phase        
	        self.ITI()
	        clock.sleep(self.phases["ITI"])
	
	        # If last trial in block, run end of block phases
	        if "end_of_block" in self.phases.keys():
	            self.end_of_block()
	            return True, self.RTs, self.correct
	            # for ms in clock.loop_for(self.phases["end_of_block"]):
	            key = event.waitKeys(keyList = ['space', 'q', 'esc'])
	            if len(key)> 0: 
	                return True, self.RTs, self.correct
	                    
	        return False, self.RTs, self.correct
	        
	
	
	    def initialization(self):
	        
	        if self.parameters["practice"] and self.trial_nr == self.parameters["practice_trials"]:
	            self.end_of_practise()
	            
	        # Perform Drift Correction
	        eyetracker.stop_recording()
	        
	        # draw_fixation(0,0,win, diameter=self.parameters["fixation_diameter"])
	        # win.flip()
	            
	        driftCheck = False 
	        while not driftCheck: 	
	            driftCheck = eyetracker.drift_correction()
	            win.flip()
	            
	        draw_fixation(0,0,win, diameter=self.parameters["fixation_diameter"])
	        win.flip()
	        eyetracker.log("fix_display")  # Logging to EDF
	        
	        
	        eyetracker.start_recording()
	
	
	        
	        # print("SOA", self.SOA)
	        # print("S1 DUR", self.phases["stimulus1"])
	
	        # logging vars to edf file 
	        # TODO: Check everything is logged. Might need to split up further
	        eyetracker.log("start_trial")
	        exp.sleep(2)
	        
	        eyetracker.log(f"TRIAL_VAR trial_nr {self.trial_nr}")
	        exp.sleep(2)
	        
	        eyetracker.log(f"TRIAL_VAR target_pos {self.target_pos}")
	        exp.sleep(2)
	        
	        eyetracker.log(f"TRIAL_VAR dist_pos {self.distractor_pos}")
	        exp.sleep(2)
	        
	        eyetracker.log(f"TRIAL_VAR background_orientation {self.bg_orientation}")
	        exp.sleep(2)  
	        
	        eyetracker.log(f"TRIAL_VAR target_salience {self.parameters['target_salience']}")
	        exp.sleep(2)  
	        
	        eyetracker.log(f"TRIAL_VAR ISI {self.SOA}")
	        exp.sleep(2)  
	        
	        eyetracker.log(f"TRIAL_VAR practice {self.parameters['practice']}")
	        exp.sleep(2)  
	        
	        eyetracker.log(f"TRIAL_VAR target_co_x {self.target_pos[0]}")
	        exp.sleep(2)  
	        
	        eyetracker.log(f"TRIAL_VAR target_co_y {self.target_pos[1]}")
	        exp.sleep(2)
	        
	        eyetracker.log(f"TRIAL_VAR distractor_co_x {self.distractor_pos[0]}")
	        exp.sleep(2)    
	        
	        eyetracker.log(f"TRIAL_VAR distractor_co_y {self.distractor_pos[1]}")
	        exp.sleep(2)  
	
	
	
	
	    def draw_stim1(self):
	        eyetracker.log("pre_display")
	        self.stimulus1.draw()
	        # If we are displaying the targets after the grid, keep showing fixation until then
	        if self.parameters["stimulus2_log"] == "target_display":
	            draw_fixation(0,0, win, diameter=self.parameters["fixation_diameter"])
	        #     eyetracker.draw_calibration_target(0,0)
	            # win.flip()
	        
	        self.t0 = core.getTime() 
	        win.flip()
	        eyetracker.log(self.parameters["stimulus1_log"])
	
	    
	    def draw_stim2(self):
	        self.stimulus1.draw()
	        self.stimulus2.draw()
	        win.flip()
	        
	        if self.SOA == 0:
	            self.t0 = core.getTime() 
	            eyetracker.log(self.parameters["stimulus1_log"])
	        
	        eyetracker.log(self.parameters["stimulus2_log"])
	        
	        response = 'fixate'
	        
	        # After stimulus 2 is drawn, we want a response 
	        # So first check for an eye movement but timeout after the set amount of time so the trial doesn't hang
	        # forever waiting for participant to make saccade (Timeout will only work with actual eyetracker)
	        for ms in clock.loop_for(self.phases["stimulus2"]):
	            try:
	                self.endtime, self.startpos, self.endpos = wait_for_saccade_end_timeout(self.phases["stimulus2"])
	            except AttributeError:
	                self.endtime, self.startpos, self.endpos = eyetracker.wait_for_saccade_end()
	           
	            if self.startpos is None: # Didn't leave fixation
	                return False
	            
	            # response_check checks where eyes move
	            # If still within fixation circle, returns fixate
	            # If the eyes move towards a location not holding either singleton, 
	            # a sound is played and warning message displayed.
	            # If it is a practice and the incorrect line is looked at, it also gives a warning message
	            response, self.RT, self.success = self.response_check()
	
	            
	            # Continue until an actual eye movement outside of the fixation AREA
	            if response != 'fixate':
	                break
	        
	        if response == 'target': 
	            self.RTs.append(self.RT)
	            return True
	        else:
	            self.RTs.append(self.RT)
	            return False
	
	        
	
	                    
	    def ITI(self):
	        draw_fixation(0,0,win, diameter=self.parameters["fixation_diameter"])
	        win.flip()
	        eyetracker.log("fix_display2")
	
	        eyetracker.log('TRIAL_VAR end_position ' + str(self.endpos))
	        eyetracker.log('TRIAL_VAR succes ' + str(self.success))
	
	        eyetracker.log('stop_trial')
	
	        # print("TRIAL_NUM", self.trial_nr)
	        results.append([self.parameters["subject_number"],
	                                                  self.trial_nr,
	                                                  self.parameters["target_orientation"],
	                                                  self.parameters["distractor_orientation"],
	                                                  self.bg_orientation,
	                                                  self.target_pos,
	                                                  self.distractor_pos,
	                                                  self.SOA,
	                                                  self.success,
	                                                  self.endpos,
	                                                  self.parameters["target_salience"],
	                                                  self.RT])
	
	        self.save_results()
	        
	    def end_of_block(self):
	        # print("RT LEN", len(RTs))
	        avg_RT = np.round(np.nanmean(self.RTs) * 1000)
	        
	        this_instruction_string = (f"This was block {self.block_num}"
	                               f"\n Your average response time was {avg_RT} ms."
	                               f"\n Well done! "
	                               f"\n\nPlease press the -spacebar- to begin.")
	        
	        if self.parameters["practice"]:
	                    this_instruction_string = (f"That concludes the practice round"
	                               f"\n\n Your average response time was {avg_RT} ms."
	                               f"\n Well done! "
	                               f"\n\nYou will now start with the actual experiment."
	                               f"\n\nGoodluck."
	                               f"\n\nPlease press the -spacebar- to begin.")
	                    
	        if self.block_num == self.parameters["num_blocks"]:
	            this_instruction_string = (f"This was the last block!"
	                               f"\n Your average response time was {avg_RT} ms."
	                               f"\n Well done! "
	                               f"\n\nPlease press the -spacebar- to end the experiment.")
	            
	
	        draw_instructions(win, this_instruction_string, keys='space')
	
	        self.save_results()
	   
	
	    def response_check(self):
	        warning_text = visual.TextStim(win, text = 'Wrong line!')
	        cur_pos = get_curr_sample(self.parameters["window_size"])
	        t1 = core.getTime()
	        RT = t1 - self.t0
	        
	        if distance(cur_pos, self.target_pos, True, win) < self.parameters["singleton_area"]:
	            response = 'target'
	            # print("TARGET POS", self.target_pos)
	            self.correct.append(1)
	            success = True
	        elif distance(cur_pos, self.distractor_pos, True, win) < self.parameters["singleton_area"]:
	            response = 'distractor'
	            # print("DIST POS", self.distractor_pos)
	            self.correct.append(0)
	            success = True
	            # print("DIST COORD", self.distractor_pos)
	            # print("TARGET COORD", self.target_pos)
	            # print("CUR_POS", cur_pos)
	            
	            if self.parameters["practice"]: 
	                clock.sleep(self.parameters["ITI_wait"])
	                my_synth.play()
	                warning_text.draw()
	                win.flip()
	                core.wait(1)
	        elif distance(cur_pos, (0,0), True, win) > self.parameters["max_dist"]:
	           clock.sleep(self.parameters["ITI_wait"])
	           success = False
	           response = None
	           
	           if self.parameters["practice"]:
	                my_synth.play()
	                warning_text = visual.TextStim(win, text='Make one eye movement to the target!')
	           # visual.Circle(win, radius=1.5 * self.parameters["max_dist"], pos=(0,0), lineColor='green', units='deg').draw()
	                warning_text.draw()
	                win.flip()
	                core.wait(1)
	        else:
	            # print("FIXATION")
	            response = 'fixation'
	            success = None
	            
	        return response, RT, success
	    
	    def fix_check(self):
	        warning_text = visual.TextStim(win, text = 'Keep fixating until targets appear!')
	        cur_pos = get_curr_sample(self.parameters["window_size"])
	        # print("FIX_CHECK_DIST", distance(cur_pos, (0,0), True, win))
	        if distance(cur_pos, (0,0), True, win) > self.parameters["max_dist"]:
	            # print("NOT AT FIX")
	            eyetracker.log("incorrect_starting_pos")
	            core.wait(0.25)
	            warning_text.draw()
	            win.flip()
	            core.wait(1)
	            return False
	        return True
	
	    def save_results(self):
	        with open(self.behavioural_file, 'wb') as handle:
	            pickle.dump(results, handle, protocol=pickle.HIGHEST_PROTOCOL)
	__end__
	set _prepare ""

define inline_script utils
	set description "Executes Python code"
	___run__
	"""
	Some Utility Functions
	"""
	
	import numpy as np
	import os, sys
	import os.path as op
	import math
	import random
	import pandas as pd
	import yaml
	
	from psychopy import visual, tools, colors, event
	import psychopy.tools.colorspacetools as ct
	from psychopy.tools.monitorunittools import deg2pix, pix2deg
	import itertools
	from typing import Optional
	from pygaze import settings
	
	
	import time
	import colorsys
	
	if TRACKER_ON:
	    import pylink
	else:
	    mouse().show_cursor(show = True)
	    
	
	def draw_fixation(x, y, screen, diameter, color=settings.FGC, pw=0):
	    r = int(diameter/2.0)
	    pos = None
	    circle = Circle(screen, radius=r-pw, edges=32, \
	                pos=pos, lineWidth=pw, lineColor=color, \
	                lineColorSpace='rgb', fillColor=color, fillColorSpace='rgb')
	    circle.draw()
	
	
	def wait_for_saccade_end_timeout(timeout=None):
	    """endtime, startpos, endpos"""
	    if not TRACKER_ON:  # Will call without timeout
	        raise AttributeError 
	    t0 = clock.time()
	    tc = timeout
	    for ms in clock.loop_for(timeout):
	        d = pylink.getEYELINK().getNextData()
	        if d == pylink.ENDSACC:
	            float_data  = pylink.getEYELINK().getFloatData()
	            tc = float_data.getTime() - eyetracker._get_eyelink_clock_async()
	            if tc > t0:
	                break
	                
	    if tc == timeout:
	        return -1, None, None
	    
	    return tc, float_data.getStartGaze(), float_data.getEndGaze()
	
	# TODO: This should return two sizes, one for vert, one for hori
	def dva_per_pix(height_cm=30, distance_cm=70, vert_res_pix=1080):
	    """ calculate degrees of visual angle per pixel,
	    to use for screen boundaries when plotting/masking
	    Parameters
	    ----------
	    height_cm : int
	        screen height
	    distance_cm: float
	        screen distance (same unit as height)
	    vert_res_pix : int
	        vertical resolution of screen
	    
	    Outputs
	    -------
	    deg_per_px : float
	        degree (dva) per pixel
	    
	    """
	
	    # screen size in degrees / vertical resolution
	    deg_per_px = (2.0 * np.degrees(np.arctan(height_cm / (2.0 * distance_cm)))) / vert_res_pix
	
	    return deg_per_px
	
	
	def circle_points(radius, n_points):
	    """ define positions in circle
	
	    Parameters
	    ----------
	    radius : list/arr
	        list of radius
	    n_points: list/arr
	        number of points per radius
	    
	    Outputs
	    -------
	    circles : list
	        list of [x,y] positions per radius
	    
	    """
	    circles = []
	
	    for r, n in zip(radius, n_points):
	        t = np.arange(0, 2 * np.pi, 2 * np.pi / float(n))  # np.linspace(0, 2 * np.pi, n)
	        x = r * np.cos(t)
	        y = r * np.sin(t)
	        circles.append(np.c_[x, y])
	
	    return circles
	
	
	def grid_coordinates(x_count: int, y_count: int, pixel_spacing: float):
	    """
	    Given the number of x, and y points and the desired spacing in degrees, return a list of pixel coordiantes
	    representing a rectangular grid
	    Parameters
	    ----------
	    x_count
	    y_count
	    pixel_spacing
	
	    Returns
	    -------
	
	    """
	    half_x = x_count // 2
	    half_y = y_count // 2
	
	    x_range = np.arange(-pixel_spacing * half_x, pixel_spacing * (1 + half_x), pixel_spacing, dtype=np.int32)
	    y_range = np.arange(-pixel_spacing * half_y, pixel_spacing * (1 + half_y), pixel_spacing, dtype=np.int32)
	
	    X, Y = np.meshgrid(x_range, y_range)
	    X = X.ravel()
	    Y = Y.ravel()
	    X = np.delete(X, [len(X)//2])
	    Y = np.delete(Y, [len(Y)//2])
	    return list(zip(X, Y))
	
	def construct_singleton_pairs(pixel_spacing: float, x_count, y_count):
	    """
	    Should return every possible combination of target, distractor pairs which are the center of each quadrant
	    I.e., the center of each half diagonal
	    Returns
	    -------
	
	    """
	    # Calculate the indices of the elements on the diagonals that are at the center of their respective quadrants
	    half_x = x_count // 2
	    half_y = y_count // 2
	
	    x_range = np.arange(-pixel_spacing * half_x, pixel_spacing * (1 + half_x), pixel_spacing, dtype=np.int32)
	    y_range = np.arange(-pixel_spacing * half_y, pixel_spacing * (1 + half_y), pixel_spacing, dtype=np.int32)
	
	    small_x = x_range[half_x//2]
	    big_x = x_range[half_x+(half_x//2)+1]
	    small_y = y_range[half_y//2]
	    big_y = y_range[half_y+(half_y//2)+1]
	    indices = []
	    indices.append((int(small_x), int(small_y)))  # top_left
	    indices.append((int(small_x), int(big_y)))  # top_right
	    indices.append((int(big_x), int(small_y)))  # bottom_left
	    indices.append((int(big_x), int(big_y)) ) # bottom_right
	
	    # Return all possible combinations where target location != distractor location
	    coords = [(indices1, indices2) for indices1 in indices for indices2 in indices if indices1 != indices2]
	    # print(coords[0])
	    # return [coords[0]]
	    return coords
	
	
	def get_grid_array(positions, ecc_range, convert2pix=True, screen=[1920, 1080],
	                   height_cm=30, distance_cm=70,
	                   constraint_type='ellipse', constraint_bounds_pix=[500, 700]):
	    """ get position array
	    needs postion list with positions per ecc
	    and ecc range
	
	    Parameters
	    ----------
	    positions : list/arr
	        list of [x,y] positions per ecc
	    ecc_range: list/arr
	        list with eccs in position
	    convert2pix: bool
	        if outputted list in pixels or not
	    constrain_type: str
	        type of position contraint to use eg: 'ellipse', 'square', 'rectangle'
	    constraint_bounds_pix: list/arr
	        bounds to constraint positions to
	    
	    Outputs
	    -------
	    pos_list : arr
	        list of [x,y] positions (pix if convert2pix == True)
	    ecc_list: arr
	        list of ecc per position pair (dva)
	    
	    """
	
	    pos_list = []
	    ecc_list = []
	
	    # if converting to pix, then need to convert the bounds to deg
	    if convert2pix:
	        constraint_bounds = constraint_bounds_pix * dva_per_pix(height_cm=height_cm,
	                                                                distance_cm=distance_cm,
	                                                                vert_res_pix=screen[-1])
	    else:
	        constraint_bounds = constraint_bounds_pix
	
	    for ind, e in enumerate(positions):
	
	        # append list of positions
	        for pos in e:
	            # check if within bounds
	            if constraint_type == 'ellipse' and \
	                    (((pos[0] ** 2) / (max(constraint_bounds) ** 2) + (pos[1] ** 2) / (
	                            min(constraint_bounds) ** 2)) <= 1):
	                pos_list.append(list(pos))
	
	                # append eccentricity of these positions
	                ecc_list.append(ecc_range[ind])
	
	    if convert2pix:
	        pos_list = pos_list / dva_per_pix(height_cm=height_cm,
	                                          distance_cm=distance_cm,
	                                          vert_res_pix=screen[-1])
	    else:
	        pos_list = np.array(pos_list)
	
	    return pos_list, np.array(ecc_list)
	    
	# def draw_input(win, instructions, wait_keys=['b'], visual_obj=[], image_path=[],
	#                       color=(1, 1, 1), font='Helvetica Neue', pos=(0, 0), height=30,  # .65,
	#                       italic=True, anchorHoriz='center', anchorVert='center'):
	#     """ draw instructions on screen
	    
	#     Parameters
	#     ----------
	#     win : object
	#         window object to draw on
	#     instructions : str
	#         instruction string to draw 
	#     key: list
	#         list of keys to skip instructions
	#     visual_obj: list
	#         if not empty, should have psychopy visual objects (to add to the display ex: side rectangles to limit display)
	        
	#     """
	
	#     text = visual.TextStim(win=win,
	#                            text=instructions,
	#                            color=color,
	#                            # font=font,
	#                            pos=pos,
	#                            height=height,
	#                            italic=italic,
	#                            anchorHoriz=anchorHoriz,
	#                            anchorVert=anchorVert
	#                            )
	
	#     # draw text 
	#     text.draw()
	
	#     if len(visual_obj) > 0:
	#         for w in range(len(visual_obj)):
	#             visual_obj[w].draw()
	
	#     if len(image_path) > 0:
	#         for _, img in enumerate(image_path):
	#             img_stim = visual.ImageStim(win=win,
	#                                         image=img,
	#                                         pos=(0, 100))
	#             img_stim.draw()
	
	#     win.flip()
	
	#     keys_pressed = event.getKeys(keyList=None)
	#     # key_pressed = event.waitKeys(keyList=keys)
	
	#     return keys_pressed
	
	
	
	def draw_instructions(win, instructions, keys=['b'], visual_obj=[], image_path=[],
	                      color=(1, 1, 1), font='Helvetica Neue', pos=(0, 0), height=30,  # .65,
	                      italic=True, anchorHoriz='center', anchorVert='center'):
	    """ draw instructions on screen
	    
	    Parameters
	    ----------
	    win : object
	        window object to draw on
	    instructions : str
	        instruction string to draw 
	    key: list
	        list of keys to skip instructions
	    visual_obj: list
	        if not empty, should have psychopy visual objects (to add to the display ex: side rectangles to limit display)
	        
	    """
	
	    text = visual.TextStim(win=win,
	                           text=instructions,
	                           color=color,
	                           # font=font,
	                           pos=pos,
	                           height=height,
	                           italic=italic,
	                           anchorHoriz=anchorHoriz,
	                           anchorVert=anchorVert
	                           )
	
	    # draw text 
	    text.draw()
	
	    if len(visual_obj) > 0:
	        for w in range(len(visual_obj)):
	            visual_obj[w].draw()
	
	    if len(image_path) > 0:
	        for _, img in enumerate(image_path):
	            img_stim = visual.ImageStim(win=win,
	                                        image=img,
	                                        pos=(0, 100))
	            img_stim.draw()
	
	    win.flip()
	
	    key_pressed = event.waitKeys(keyList=keys)
	
	    return key_pressed
	
	def get_curr_sample(screen_dims):
	    curPos = eyetracker.sample()	
	    # print("CUR_SAMP", curPos)
	    # print("SCREEN_DIMS", screen_dims)
	    x_sample = curPos[0] - screen_dims[0]/2
	    y_sample = -(curPos[1] - screen_dims[1]/2)
	    return (x_sample, y_sample)
	    
	def distance(p1, p2, deg=False, win=None):
	    dist = np.sqrt((p1[0] - p2[0])**2 + (p1[1] - p2[1])**2)
	    if deg:
	        if win is None:
	            raise ValueError
	        return pix2deg(dist, win.monitor)
	    else:
	        return dist
	__end__
	set _prepare ""

