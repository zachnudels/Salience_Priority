---
API: 2.1
OpenSesame: 3.3.14
Platform: nt
---
set width 1920
set uniform_coordinates yes
set title "New experiment"
set subject_parity even
set subject_nr 0
set start experiment
set sound_sample_size -16
set sound_freq 48000
set sound_channels 2
set sound_buf_size 1024
set sampler_backend legacy
set round_decimals 2
set psychopy_monitor testMonitor
set mouse_backend psycho
set keyboard_backend psycho
set height 1080
set fullscreen no
set form_clicks no
set foreground white
set font_underline no
set font_size 18
set font_italic no
set font_family mono
set font_bold no
set experiment_path "C:/Users/RA-Eyelink/Salience_Priority"
set disable_garbage_collection yes
set description "The main experiment item"
set coordinates uniform
set compensation 0
set color_backend psycho
set clock_backend psycho
set canvas_backend psycho
set background black

define inline_script constants
	set description "Executes Python code"
	set _run ""
	___prepare__
	debug = False
	exp_num = 2
	cwd =  "C:\\Users\\RA-Eyelink\\Salience_Priority"
	cwd_ = '/Users/zach/RA_2023/Salience_Priority/experiment'
	results = []
	to_target_list = []
	RTs = []
	
	print(cwd)
	__end__

define sequence experiment
	set flush_keyboard yes
	set description "Runs a number of items in sequence"
	run new_pygaze_init always
	run constants always
	run utils always
	run singleton_session always
	run singleton_trial always
	run main always

define inline_script main
	set description "Executes Python code"
	___run__
	from psychopy import visual, core, event
	from psychopy.tools.monitorunittools import deg2pix
	import random
	import numpy as np
	
	import sys
	import os
	import os.path as op
	
	import yaml
	
	
	with open(op.join(cwd, 'experiment_settings.yml'), 'r') as f_in:
	    params = yaml.safe_load(f_in)
	    
	
	# take user input
	
	# # define participant number and open json parameter file
	# if len(sys.argv) < 2:
	#     raise NameError('Please add subject number (ex:1) '
	#                     'as 1st argument in the command line!')
	
	# elif len(sys.argv) < 3:
	#     raise NameError('Please add session number (ex:1) '
	#                     'as 2nd argument in the command line!')
	
	sj_num = self.get('subject_nr') # subject number
	
	
	
	# TODO: Check if practice always in same file?
	# task name dictionary
	print(f"Running experiment {exp_num} for subject {sj_num}")
	
	# make output dir
	if params['paths']['curr_dir'] == 'lab':
	    output_dir = op.join(params['paths']['data_pth']['lab'], 'output', 'sourcedata', 'sub-{sj}'.format(sj=sj_num))
	else:
	    base_dir = op.split(cwd)[0]  # main path for all folders of project
	    output_dir = op.join(base_dir, 'output', 'sourcedata', 'sub-{sj}'.format(sj=sj_num))
	
	# if output path doesn't exist, create it
	if not op.isdir(output_dir):
	    os.makedirs(output_dir)
	print('saving files in %s' % output_dir)
	
	# if file already exists
	output_str = str(sj_num)
	behav_file = op.join(output_dir, f"behavioral_data_mieke{sj_num}.pickle")
	
	if op.exists(behav_file):
	    print('file already exists!')
	
	    # overwrite = ''
	    # while overwrite not in ('y', 'yes', 'n', 'no'):
	    #     overwrite = input('overwrite %s\n(y/yes/n/no)?: ' % behav_file)
	
	    # if overwrite in ['no', 'n']:
	    #     raise NameError('Run %s already in directory\nstopping experiment!' % behav_file)
	
	exp_sess = SingletonSession(output_str=output_str,
	                            output_dir=output_dir,
	                            eyetracker_on=True,
	                            settings=params,
	                            behav_file=behav_file,
	                            subject_number=sj_num,
	                            exp_num=exp_num,
	                            debug=debug)
	
	exp_sess.run()
	__end__
	set _prepare ""

define pygaze_init new_pygaze_init
	set tracker_type EyeLink
	set tobiiglasses_udpport 49152
	set tobiiglasses_address "192.168.71.50"
	set smi_send_port 4444
	set smi_recv_port 5555
	set smi_ip "127.0.0.1"
	set sacc_vel_thr 35
	set sacc_acc_thr 9500
	set eyelink_pupil_size_mode area
	set eyelink_force_drift_correct yes
	set description "Initialize and calibrate eye tracker"
	set calibrate yes
	set calbeep no
	set alea_api_key "Contact Alea for an API key"
	set alea_animated_calibration no
	set _logfile automatic

define inline_script singleton_session
	set description "Executes Python code"
	___run__
	from typing import List, Tuple
	import os 
	
	import numpy as np
	from copy import deepcopy
	from psychopy import visual
	from psychopy import prefs
	from psychopy import sound
	# prefs.hardware['audioLib'] = ['PTB']
	from psychopy.tools.monitorunittools import deg2pix
	
	# from singleton_trial import SingletonTrial
	# from utils import grid_coordinates, dva_per_pix, draw_instructions, construct_singleton_pairs
	
	Coordinate = Tuple[int, int]
	
	
	class SingletonSession():
	    def __init__(self, output_str, output_dir, settings, behav_file, eyetracker_on, subject_number, exp_num, debug):
	
	        self.results = []
	        self.practice_trials = []
	        self.trials = []
	        self.trial_parameters = dict()
	        self.trial_parameters["subject_number"] = subject_number
	        self.to_target_list = []
	        self.exp_num = exp_num
	        self.debug = debug
	        self.screen = np.array([win.size[0], win.size[1]])
	        self.settings = settings
	
	        if subject_number % 2 == 0:
	            self.trial_parameters["target_orientation"] = self.settings["stimuli"]["singleton_orientation"][0]
	            self.trial_parameters["distractor_orientation"] = self.settings["stimuli"]["singleton_orientation"][1]
	
	        else:
	            self.trial_parameters["target_orientation"] = self.settings["stimuli"]["singleton_orientation"][1]
	            self.trial_parameters["distractor_orientation"] = self.settings["stimuli"]["singleton_orientation"][0]
	
	        self.exp_str = f"exp{self.exp_num}"
	        self.num_reps = self.settings["study"][self.exp_str]["num_reps"]
	        self.bg_orientations = self.settings["stimuli"]["bg_orientation"]
	        self.SOAs = self.settings["study"][self.exp_str]["SOAs"]#[SOA*1e-3 for SOA in self.settings["study"][self.exp_str]["SOAs"]]
	        print(self.SOAs)
	        self.num_blocks = self.settings["study"][self.exp_str]["num_blocks"]
	
	
	        self.behav_file = behav_file
	
	        print(self.trial_parameters["target_orientation"], self.trial_parameters["distractor_orientation"])
	
	        self.trial_parameters["window_size"] = self.settings["window_extra"]["size"]
	        self.trial_parameters["practice_trials"] = self.settings["study"][f"exp{self.exp_num}"]["practice_trials"]
	        self.trial_parameters["ITI_wait"] = self.settings["trial_info"]["ITI_stim_2"]
	
	        self.instructions = {
	            "target_direction": "left" if self.trial_parameters["target_orientation"] < 0 else "right",
	            "target_symbol": "\\" if self.trial_parameters["target_orientation"] < 0 else "/",
	            "distractor_direction": "left" if self.trial_parameters["distractor_orientation"] < 0 else "right",
	            "distractor_symbol": "\\" if self.trial_parameters["distractor_orientation"] < 0 else "/",
	        }
	
	        print(self.instructions)
	
	                # TODO: Fixation point
	        line_size_pix = deg2pix(self.settings["stimuli"]["fix_line_size_deg"], win.monitor)
	        print("LINE SIZE", line_size_pix)
	
	        line_width_pix = deg2pix(self.settings["stimuli"]["fix_line_width_deg"], win.monitor)
	        print("LINE WIDTH", line_width_pix)
	
	        self.fixation = visual.ShapeStim(win,
	                                         vertices=((0, -line_size_pix / 2), (0, line_size_pix / 2),
	                                                   (0, 0),
	                                                   (-line_size_pix / 2, 0), (line_size_pix / 2, 0)),
	                                         lineWidth=line_width_pix,
	                                         closeShape=False,
	                                         lineColor=self.settings['stimuli']['fix_color'])
	
	        self.max_dist = self.settings["stimuli"]["fix_check_rad"]
	
	        self.trial_parameters["max_dist"] = self.max_dist
	        print("MAX_DIST", self.max_dist)
	
	        ########################
	
	    def run(self):
	        
	        RTs = []
	        correct = []
	        self.create_trials()
	        
	
	        # draw instructions wait a few seconds
	        this_instruction_string = (f"Instructions"
	                                   f"\n\nThe task is to move your eyes to a line that is rotated to the "
	                                   f"{self.instructions['target_direction']} ({self.instructions['target_symbol']})."
	                                   f"\nTry not to make eye movements to the distractor line that is rotated to the "
	                                   f"{self.instructions['distractor_direction']} "
	                                   f"({self.instructions['distractor_symbol']})."
	                                   f"\n Before each trial, press the -spacebar- to start"
	                                   f"\n\n Press the -spacebar- to continue.")
	
	        draw_instructions(win, this_instruction_string, keys='space')
	
	        this_instruction_string = (f"\nTry to be as fast and accurate as possible!"
	                                   f"\nMove as soon as you see the target (which is also when the fixation dot in the "
	                                   f"middle disappears)"
	                                   f"\n\n\nPlease press the -spacebar- to continue")
	
	        draw_instructions(win, this_instruction_string, keys='space')
	
	        this_instruction_string = (f"You will now start with a practice session."
	                                   f"\n\nYou will get a warning if you select the distractor instead of the target"
	                                   f"\nYou will also get a warning if you make more than one eye movement to reach the "
	                                   f"target"
	                                   f"\n\nPlease press the -spacebar- to begin.")
	
	        draw_instructions(win, this_instruction_string, keys='space')
	
	        if not self.debug:
	            for trial in self.practice_trials:
	                end_of_block, RTs, correct = trial.run(RTs, correct)
	                if end_of_block:
	                    RTs = []
	                    correct = []
	
	
	        # if self.eyetracker_on:
	        #     eyetracker.start_recording()
	
	        for trial in self.trials:
	            end_of_block, RTs, correct = trial.run(RTs, correct)
	            if end_of_block:
	                RTs = []
	                correct = []
	        
	
	
	    def create_trials(self):
	        # TODO: Check this - I think Ines used vertical and psychopy uses horizontal to convert
	        pixel_l = deg2pix(self.settings["stimuli"]["line_length"], win.monitor)
	
	        pixel_w = deg2pix(self.settings["stimuli"]["line_width"], win.monitor)
	        pixel_spacing = deg2pix(self.settings["stimuli"]["spacing"], win.monitor) + np.max([pixel_l, pixel_w])
	
	        coordinates = grid_coordinates(self.settings["stimuli"]["x_count"],
	                                       self.settings["stimuli"]["y_count"],
	                                       pixel_spacing)
	
	        possible_singleton_locations = construct_singleton_pairs(pixel_spacing,
	                                                                 self.settings["stimuli"]["x_count"],
	                                                                 self.settings["stimuli"]["y_count"])
	
	
	        # # init variables for feedback
	        #
	        # check if they moved their eyes before targets are shown
	        # fixation_circle = visual.Circle(win, radius=self.max_dist, pos=(0, 0), units='deg')
	
	        # Save memory - don't construct for each rep
	        possible_grids = dict()
	        possible_singletons = dict()
	        # target_circles = dict()
	        # dist_circles = dict()
	        # target_big_circles = dict()
	        # dist_big_circles = dict()
	
	        for bg_orientation in self.bg_orientations:
	            for target_coord, distractor_coord in possible_singleton_locations:
	                grid_coords = [coordinate for coordinate in coordinates
	                               if coordinate != target_coord and coordinate != distractor_coord]
	                key = f"{bg_orientation}{target_coord}{distractor_coord}"
	
	                possible_grids[key] = visual.ElementArrayStim(win,
	                                                              nElements=len(grid_coords),
	                                                              xys=grid_coords,
	                                                              oris=bg_orientation,
	                                                              units='pix',
	                                                              autoLog=False,
	                                                              sizes=(pixel_w, pixel_l),
	                                                              elementMask=None,
	                                                              elementTex=None,
	                                                              interpolate=False)
	                possible_singletons[key] = visual.ElementArrayStim(win,
	                                                                   nElements=2,
	                                                                   xys=[target_coord, distractor_coord],
	                                                                   oris=[self.trial_parameters["target_orientation"],
	                                                                         self.trial_parameters[
	                                                                             "distractor_orientation"]],
	                                                                   units='pix',
	                                                                   autoLog=False,
	                                                                   sizes=(pixel_w, pixel_l),
	                                                                   elementMask=None,
	                                                                   elementTex=None)
	                # target_circles[key] = visual.Circle(win, radius=50, pos=target_coord, lineColor='green')
	                # dist_circles[key] = visual.Circle(win, radius=50, pos=distractor_coord, lineColor='blue')
	                # target_big_circles[key] = visual.Circle(win, radius=107, pos=target_coord, lineColor='green')
	                # dist_big_circles[key] = visual.Circle(win, radius=107, pos=distractor_coord, lineColor='blue')
	
	        num_trials = (self.num_reps *
	                      len(self.bg_orientations) *
	                      len(self.SOAs) *
	                      len(possible_singleton_locations))
	
	        print("num_trials: ", num_trials)
	        if num_trials % self.num_blocks != 0:
	            raise RuntimeError(f"{self.num_blocks} blocks won't divide {num_trials} trials evenly. Change experiment settings.")
	            self.close()
	
	        trials_per_block = num_trials // self.num_blocks
	        print("NUM TRIALS", num_trials)
	        print("NUM BLOCKS", self.num_blocks)
	        print("TRIALS PER BLOCK", trials_per_block)
	        self.trial_parameters["num_blocks"] = self.num_blocks
	        self.trial_parameters["singleton_area"] = self.settings["stimuli"]["singleton_area"]
	
	        trial_indices = np.arange(num_trials)
	        np.random.shuffle(trial_indices)  # Randomise trials
	        trial_i = 0
	        
	        practice_trial_indices = np.arange(num_trials)
	        np.random.shuffle(practice_trial_indices)
	        
	
	        tone = sound.Sound('A')
	
	
	
	
	        for rep in range(self.num_reps):
	            for target_coord, distractor_coord in possible_singleton_locations:
	                for bg_orientation in self.bg_orientations:
	                    for SOA in self.SOAs:
	                    
	
	                        trial_num = trial_indices[trial_i]
	                        block_num = (trial_num // trials_per_block) + 1
	
	                        key = f"{bg_orientation}{target_coord}{distractor_coord}"
	
	                        _trial_parameters = deepcopy(self.trial_parameters)
	
	                        # target salient or  not
	                        if abs(self.trial_parameters["target_orientation"] - bg_orientation) > \
	                                abs(self.trial_parameters["distractor_orientation"] - bg_orientation):
	                            _trial_parameters["target_salience"] = "high"
	                        else:
	                            _trial_parameters["target_salience"] = "low"
	
	                        _trial_parameters["target_pos"] = target_coord
	                        _trial_parameters["distractor_pos"] = distractor_coord
	                        # print(target_coord, distractor_coord)
	                        _trial_parameters["bg_orientation"] = bg_orientation
	                        _trial_parameters["SOA"] = SOA
	
	                        _trial_parameters["practice"] = False
	
	                        grid = possible_grids[key]
	                        singletons = possible_singletons[key]
	
	                        initialization_time = self.settings["trial_info"]["initialization_time"] 
	
	                        if SOA < 0:
	                            stimulus1 = grid
	                            _trial_parameters["stimulus1_log"] = "stimuli_show"
	                            stimulus2 = singletons
	                            _trial_parameters["stimulus2_log"] = "target_display"
	                            initialization_time += SOA # Adding a negative SOA will decrease time to ensure singletons presented after same duration
	                        else:
	                            stimulus1 = singletons
	                            _trial_parameters["stimulus1_log"] = "target_display"
	                            stimulus2 = grid
	                            _trial_parameters["stimulus2_log"] = "stimuli_show"
	
	                        phases = {
	                            "initialization": initialization_time,
	                            "stimulus1": np.abs(SOA),
	                            "stimulus2": self.settings["trial_info"]["max_response_time"],
	                            "ITI": self.settings["trial_info"]["ITI"] + np.random.uniform(-100, 100) - self.trial_parameters["ITI_wait"],
	                        }
	                        
	                        trial = SingletonTrial(trial_nr=trial_num,
	                                                          block_num=block_num,
	                                                          phases=phases,
	                                                          parameters=_trial_parameters,
	                                                          stimulus1=stimulus1,
	                                                          stimulus2=stimulus2,
	                                                          tone=tone,
	                                                          debug=self.debug,
	                                                          behavioural_file=self.behav_file)
	                                                          # fixation_circle=fixation_circle)
	                                                          # target_circle=target_circles[key],
	                                                          # distractor_circle=dist_circles[key],
	                                                          # target_circle_big=target_big_circles[key],
	                                                          # distractor_circle_big=dist_big_circles[key])
	
	                        if (trial_num + 1) % trials_per_block == 0:
	                            trial.phases["end_of_block"] = 1000
	
	                        self.trials.append(trial)
	                        
	                        # if trial_i < self.settings["study"][self.exp_str]["practice_trials"]:
	                        practice_trial_num = practice_trial_indices[trial_i]
	                        practice_trial = SingletonTrial(trial_nr=practice_trial_num,
	                                                          block_num=0,
	                                                          phases=phases,
	                                                          parameters=_trial_parameters,
	                                                          stimulus1=stimulus1,
	                                                          stimulus2=stimulus2,
	                                                          tone=tone,
	                                                          debug=self.debug,
	                                                          behavioural_file=self.behav_file)
	                                                          # fixation_circle=fixation_circle)
	                                                          # target_circle=target_circles[key],
	                                                          # distractor_circle=dist_circles[key],
	                                                          # target_circle_big=target_big_circles[key],
	                                                          # distractor_circle_big=dist_big_circles[key])
	                        
	                        if practice_trial_num == self.settings["study"][self.exp_str]["practice_trials"] - 1:
	                            practice_trial.phases["end_of_block"] = 1000
	                            
	                        practice_trial.parameters["practice"] = True
	                        self.practice_trials.append(practice_trial)
	                        
	                        trial_i += 1
	                            
	
	        # if not self.debug:
	        # TODO Check how to construct practice trials
	
	        self.trials = sorted(self.trials, key=lambda trial: trial.trial_nr)
	        self.practice_trials = sorted(self.practice_trials, key=lambda trial: trial.trial_nr)
	        self.practice_trials = self.practice_trials[:self.settings["study"][self.exp_str]["practice_trials"]]
	
	        # print("TRIALS")
	        # for trial in self.trials:
	        #     print(trial.trial_nr, trial.block_num, "end_of_block" in trial.phases.keys(), trial.SOA)
	
	        print("PRACTICE TRIALS")
	        for trial in self.practice_trials:
	            print(trial.trial_nr, trial.block_num, "end_of_block" in trial.phases.keys(), trial.SOA, trial.bg_orientation)
	
	
	
	        # for i in range(len(self.practice_trials[0].phase_durations)):
	        #     print(self.practice_trials[0].phase_names[i], self.practice_trials[0].phase_durations[i])
	
	            # TODO: Change what makes it a practice: longer time somewhere?
	            # practice_trial.phase_duration
	
	        # self.results = np.matrix(np.zeros([len(self.trials), 12]), dtype=object)
	__end__
	set _prepare ""

define inline_script singleton_trial
	set description "Executes Python code"
	___run__
	import numpy as np
	
	# import pylink
	from typing import Dict, List, Optional, Tuple
	
	import pickle
	# import psychtoolbox as ptb
	from psychopy.visual.elementarray import ElementArrayStim
	from psychopy.visual.circle import Circle
	from psychopy import event, visual
	from psychopy import sound
	from openexp.synth import synth
	my_synth = synth(self.experiment, osc = "sine", freq = 500, attack = 0, length = 100)
	# this is for dummy mode, comment if you are actually testing! 
	my_mouse = mouse()
	my_mouse.show_cursor(show = True)
	
	# import utils
	
	
	# Opening edf files:
	# open powershell in the folder
	# command: edf2asc <filename> -e(events)/s(samples)
	
	
	class SingletonTrial():
	    def __init__(self,
	                 trial_nr: int,
	                 block_num: int,
	                 phases: Dict[str, float],
	                 parameters: Dict,
	                 stimulus1: ElementArrayStim,
	                 stimulus2: ElementArrayStim,
	                 tone: sound.Sound,
	                 behavioural_file: str,
	                 debug: bool):
	                 # fixation_circle: Circle,
	                 # target_circle: Circle,
	                 # distractor_circle: Circle,
	                 # target_circle_big: Circle,
	                 # distractor_circle_big: Circle):
	
	
	        self.RT = None
	        self.success = None
	        self.endpos = None
	        self.startpos = None
	        self.endtime = None
	        self.t0 = None
	        self.response = None
	        self.target_pos = parameters['target_pos']
	        self.distractor_pos = parameters['distractor_pos']
	        self.SOA = parameters['SOA']
	        self.bg_orientation = parameters['bg_orientation']
	        self.target_orientation = parameters["target_orientation"]
	        self.distractor_orientation = parameters["distractor_orientation"]
	        
	        # self.target_circle = target_circle
	        # self.target_circle_big = target_circle_big
	        # self.distractor_circle = distractor_circle
	        # self.distractor_circle_big = distractor_circle_big
	        # self.fixation_circle = fixation_circle
	
	        # Delete tuples from parameters since they cannot be logged
	        # del parameters["target_pos"]
	        # del parameters["distractor_pos"]
	
	
	        self.stimulus1 = stimulus1
	        self.stimulus2 = stimulus2
	
	        self.trial_nr = trial_nr
	        self.block_num = block_num
	
	        self.parameters = dict(parameters)
	
	        self.a_sound = tone
	
	        self.behavioural_file = behavioural_file
	        self.debug = debug
	        self.phases = dict(phases)
	
	        # self.singletons = singletons
	        # self.target_stim = target_stim
	        # self.distractor_stim = distractor_stim
	
	    def initialization(self):
	        
	        if self.parameters["practice"] and self.trial_nr == self.parameters["practice_trials"]:
	            self.end_of_practise()
	            
	        eyetracker.stop_recording()
	            
	        driftCheck = False 
	        while not driftCheck: 	
	            driftCheck = eyetracker.drift_correction()
	            win.flip()
	        
	        eyetracker.start_recording()
	
	            # self.session.tracker.sendMessage(
	            #     f"trial {str(self.trial_nr)}_{str(round(np.nanmean(self.session.RTs) * 1000))}_{str(np.round(np.nanmean(self.to_target_list) * 100))}")
	
	            # self.session.win.flip()
	        eyetracker.log("fix_display")  # Logging to EDF
	        
	        print("SOA", self.SOA)
	        print("S1 DUR", self.phases["stimulus1"])
	
	        # logging vars to edf file
	        # TODO: to ensure logging works - CHECK everything is being logged. Maybe can make one long string with returns
	        # TODO: in it. Check with Elle if this would still work for Analysis
	        # Maybe check docs to see how many log calls can be made sequentially
	        initialization_log_string = f"start_trial" \
	                                    f"\nTRIAL_VAR trial_nr {self.trial_nr}" \
	                                    f"\nTRIAL_VAR target_pos {self.target_pos}" \
	                                    f"\nTRIAL_VAR dist_pos {self.distractor_pos}" \
	                                    f"\nTRIAL_VAR target_co_x {self.target_pos[0]}" \
	                                    f"\nTRIAL_VAR target_co_y {self.target_pos[1]}"
	       
	        eyetracker.log(initialization_log_string)
	       
	        exp.sleep(2)
	        
	        initialization_log_string = f"\nTRIAL_VAR distractor_co_x {self.distractor_pos[0]}" \
	                                    f"\nTRIAL_VAR distractor_co_y {self.distractor_pos[1]}" \
	                                    f"\nTRIAL_VAR background_orientation {self.bg_orientation}" \
	                                    f"\nTRIAL_VAR ISI {self.SOA}" \
	                                    f"\nTRIAL_VAR practice {self.parameters['practice']}" \
	                                    f"\nTRIAL_VAR target_salience {self.parameters['target_salience']}"
	
	        eyetracker.log(initialization_log_string)
	
	        # print("End initialization")
	        # self.session.fixation.draw()
	        self.draw_fixation((0,0),10)
	        win.flip()
	        
	    def draw_stim1(self):
	        self.stimulus1.draw()
	            # print("Draw stim1")
	        
	        self.t0 = core.getTime() 
	        win.flip()# TODO: Check if t0 needs to be accurate (target displayed rather than either)
	        eyetracker.log(self.parameters["stimulus1_log"])
	
	    
	    def draw_stim2(self):
	        self.stimulus1.draw()
	        self.stimulus2.draw()
	        # visual.Circle(win, radius=self.parameters["max_dist"], pos=self.target_pos, lineColor='green', units='deg').draw()
	        # visual.Circle(win, radius=self.parameters["max_dist"], pos=self.distractor_pos, lineColor='green', units='deg').draw()
	        # visual.Circle(win, radius=self.parameters["max_dist"], pos=(0,0), lineColor='green', units='deg').draw()
	        
	        win.flip()
	        
	        eyetracker.log(self.parameters["stimulus2_log"])
	        
	        response = 'fixate'
	        
	        
	        for ms in clock.loop_for(self.phases["stimulus2"]):
	            try:
	                self.endtime, self.startpos, self.endpos = wait_for_saccade_end_timeout(self.phases["stimulus2"])
	            except AttributeError:
	                self.endtime, self.startpos, self.endpos = eyetracker.wait_for_saccade_end()
	            if self.startpos is None: # Didn't leave fixation
	                return False
	            response, RT, self.success = self.response_check()
	            if response != 'fixate':
	                break
	        
	        if response is not None and response != 'fixate':
	            # print("RESPONSE CAPTURED", response)
	            if response == 'distractor':
	                return False
	            
	            self.RTs.append(RT)
	        else:
	            return False
	
	        
	        return True
	                    
	    def ITI(self):
	        self.draw_fixation((0,0),10)
	        win.flip()
	        # self.success = self.check_saccade(self.endpos)
	        eyetracker.log('TRIAL_VAR end_position ' + str(self.endpos))
	        eyetracker.log('TRIAL_VAR succes ' + str(self.success))
	
	        eyetracker.log('stop_trial')
	        # self.session.tracker.stop_recording()
	        print("TRIAL_NUM", self.trial_nr)
	        results.append([self.parameters["subject_number"],
	                                                  self.trial_nr,
	                                                  self.parameters["target_orientation"],
	                                                  self.parameters["distractor_orientation"],
	                                                  self.bg_orientation,
	                                                  self.target_pos,
	                                                  self.distractor_pos,
	                                                  self.SOA,
	                                                  self.success,
	                                                  self.endpos,
	                                                  self.parameters["target_salience"],
	                                                  self.RT])
	
	        self.save_results()
	        
	    def end_of_block(self):
	        # print("RT LEN", len(RTs))
	        avg_RT = np.round(np.nanmean(self.RTs) * 1000)
	        # accuracy = np.round(np.nanmean(self.correct) * 100)
	        
	        this_instruction_string = (f"This was block {self.block_num}"
	                               # f"\n\n Your accuracy was {accuracy}%"
	                               f"\n Your average response time was {avg_RT} ms."
	                               f"\n Well done! "
	                               f"\n\nPlease press the -spacebar- to begin.")
	        
	        if self.parameters["practice"]:
	                    this_instruction_string = (f"That concludes the practice round"
	                               # f"\n\n Your accuracy was {accuracy}%"
	                               f"\n\n Your average response time was {avg_RT} ms."
	                               f"\n Well done! "
	                               f"\n\nYou will now start with the actual experiment."
	                               f"\n\nGoodluck."
	                               f"\n\nPlease press the -spacebar- to begin.")
	                    
	        if self.block_num == self.parameters["num_blocks"]:
	            this_instruction_string = (f"This was the last block!"
	                               # f"\n\n Your accuracy was {accuracy}%"
	                               f"\n Your average response time was {avg_RT} ms."
	                               f"\n Well done! "
	                               f"\n\nPlease press the -spacebar- to end the experiment.")
	            
	
	
	        draw_instructions(win, this_instruction_string, keys='space')
	
	        # RTs = []
	        self.save_results()
	        
	        
	
	    
	
	    
	    def run(self, RTs, correct):
	        
	
	        self.RTs = RTs
	        print("RTs", self.RTs)
	        print("CORRECT", correct)
	        print("BLOCK_INFO", self.block_num, self.parameters["num_blocks"])
	        self.correct = correct
	        
	        print("practice", self.parameters["practice"])
	        
	        
	        self.initialization()
	        
	        # core.wait(self.phases["initialization"])
	        for ms in clock.loop_for(self.phases["initialization"]):
	            if not self.fix_check():
	                self.ITI()
	                clock.sleep(self.phases["ITI"])
	                return False, self.RTs, self.correct
	        
	        
	        self.draw_stim1()
	        
	        # print("STIM 1 DRAWN")
	        
	        
	        for ms in clock.loop_for(self.phases["stimulus1"]):
	            # print("MS", ms)
	            if self.parameters["stimulus2_log"] == "target_display":
	                if not self.fix_check():
	                    self.ITI()
	                    clock.sleep(self.phases["ITI"])
	                    return False, self.RTs, self.correct
	        
	        
	       
	        
	        self.draw_stim2()
	        
	        clock.sleep(self.parameters["ITI_wait"])  # Wait before removing grid, otherwise too fast
	        self.ITI()
	        
	        clock.sleep(self.phases["ITI"])
	        
	        # print("STIM 2 DRAWN")
	        
	        # clock.sleep(self.phases["stimulus2"])
	        
	
	    
	        
	        #         key = event.getKeys(keyList = ['space'])
	        # if len(key)> 0: 
	        #     if key[0] =='space': 
	        #         return
	        
	        if "end_of_block" in self.phases.keys():
	            self.end_of_block()
	            return True, self.RTs, self.correct
	            # for ms in clock.loop_for(self.phases["end_of_block"]):
	            key = event.waitKeys(keyList = ['space', 'q', 'esc'])
	            if len(key)> 0: 
	                return True, self.RTs, self.correct
	                    
	        return False, self.RTs, self.correct
	        
	        # print(self.phase)
	        # for i in range(len(self.phase_names)):
	        #     print(self.phase_names[i], self.phase_durations[i])
	        # print('phase', self.phase_names[int(self.phase)])
	        # print(self.parameters)
	        # TODO: CHECK + What happens at block end??
	        # check to see if it's time for a break
	
	
	
	            # self.session.tracker deals with everything here
	            
	
	
	            # session.tracker.sendMessage("TRIAL_VAR target_salience %s" % target_salience)
	            # exp.sleep(2)
	
	
	
	    
	
	        # print("Draw fixaxtion")
	        # utils.draw_instructions(self.session.win, "TEST", keys='space')
	        
	        # print(self.parameters)
	
	        # saving the results matrix
	        # print(blue)
	
	        
	
	    def response_check(self):
	        warning_text = visual.TextStim(win, text = 'Wrong line!')
	        cur_pos = get_curr_sample(self.parameters["window_size"])
	        t1 = core.getTime()
	        RT = t1 - self.t0
	        
	        if distance(cur_pos, self.target_pos, True, win) < self.parameters["singleton_area"]:
	            response = 'target'
	            print("TARGET POS", self.target_pos)
	            self.correct.append(1)
	            success = True
	        elif distance(cur_pos, self.distractor_pos, True, win) < self.parameters["singleton_area"]:
	            response = 'distractor'
	            print("DIST POS", self.distractor_pos)
	            self.correct.append(0)
	            success = True
	            # print("DIST COORD", self.distractor_pos)
	            # print("TARGET COORD", self.target_pos)
	            # print("CUR_POS", cur_pos)
	            
	            if self.parameters["practice"]: 
	                clock.sleep(self.parameters["ITI_wait"])
	                my_synth.play()
	                warning_text.draw()
	                win.flip()
	                core.wait(1)
	        elif distance(cur_pos, (0,0), True, win) > self.parameters["max_dist"]:
	           clock.sleep(self.parameters["ITI_wait"])
	           success = False
	           my_synth.play()
	           warning_text = visual.TextStim(win, text='Make one eye movement to the target!')
	           # visual.Circle(win, radius=1.5 * self.parameters["max_dist"], pos=(0,0), lineColor='green', units='deg').draw()
	           warning_text.draw()
	           win.flip()
	           core.wait(1)
	           response = None
	        else:
	            print("FIXATION")
	            response = 'fixation'
	            success = None
	        
	        
	            
	        return response, RT, success
	    
	    def fix_check(self):
	        warning_text = visual.TextStim(win, text = 'Keep fixating until targets appear!')
	        cur_pos = get_curr_sample(self.parameters["window_size"])
	        # print("FIX_CHECK_DIST", distance(cur_pos, (0,0), True, win))
	        if distance(cur_pos, (0,0), True, win) > self.parameters["max_dist"]:
	            print("NOT AT FIX")
	            eyetracker.log("incorrect_starting_pos")
	            core.wait(0.25)
	            # self.fixation_circle.draw()
	            warning_text.draw()
	            win.flip()
	            core.wait(1)
	            return False
	        return True
	        
	        # print("FIX CHECK CUR POS", cur_pos)
	        # print("FIX CIRCLE", self.fixation_circle.pos)
	     
	
	        
	
	    def draw_fixation(self, pos, lineSize, draw_cross=True, color='white'):
	        t = lineSize / 2.0
	        vertical_line = visual.Line(win, start=(pos[0], pos[1] - t), end=(pos[0], pos[1] + t),
	                                    lineColor=color)
	        horizontal_line = visual.Line(win, start=(pos[0] - t, pos[1]), end=(pos[0] + t, pos[1]),
	                                      lineColor=color)
	
	        if draw_cross:
	            vertical_line.draw()
	            horizontal_line.draw()
	
	    def save_results(self):
	        with open(self.behavioural_file, 'wb') as handle:
	            pickle.dump(results, handle, protocol=pickle.HIGHEST_PROTOCOL)
	
	
	
	    def check_saccade(self, endpos):
	        """
	        Check whether movement is one continuous saccade, not broken up
	        Parameters
	        ----------
	        endpos
	
	        Returns
	        -------
	
	        """
	        if endpos is None:
	            return False
	        
	        cur_pos = get_curr_sample(self.parameters["window_size"])
	
	        # TODO: Use distance instead of circle
	        if distance(cur_pos, self.target_pos, True, win) < 2 * self.parameters["max_dist"] or \
	            distance(cur_pos, self.distractor_pos, True, win) < 2: 
	            success = True
	        else:
	            success = False
	            warning_text = visual.TextStim(win, text='Make one eye movement to the target!')
	            warning_text.draw()
	            win.flip()
	            
	        return success
	
	    # def get_events(self):
	    #     """ Logs responses/triggers """
	    #     for ev, t in event.getKeys(
	    #             timeStamped=clock):  # list of of (keyname, time) relative to Clock’s last reset
	    #         if len(ev) > 0:
	    #             if ev in ['q']:
	    #                 print('trial canceled by user')
	    #                 close()
	    #                 quit()
	
	    #             elif ev in['space'] and self.phase_names[int(self.phase)] == "end_of_block":
	    #                 self.stop_phase()
	
	#
	# class PracticeSingletonTrial(SingletonTrial):
	#     def __init__(self,
	#                  session: Session,
	#                  trial_nr: int,
	#                  phase_durations: Tuple[int],
	#                  phase_names: Optional[Tuple[str]],
	#                  parameters: Optional[Dict]):
	#         super().__init__(session, trial_nr, phase_durations, phase_names, parameters)
	#
	#         """
	#         if trial_nr == session.settings.nr_practice_trials:
	#             end_of_practice()
	#         """
	#
	#         def end_of_practise():
	#             text1 = visual.TextStim(self.session.win, text='This is the end of the practise block', pos=(0, 200))
	#             text2 = visual.TextStim(self.session.win,
	#                                     text='From now on you will only hear a beep if you select the distractor (no longer the text Wrong Line!)',
	#                                     pos=(0, -0))
	#             text3 = visual.TextStim(self.session.win, text='Press c to continue', pos=(0, -200))
	#
	#             text1.draw()
	#             text2.draw()
	#             text3.draw()
	#             self.session.win.flip()
	#
	#             event.waitKeys(keyList=['c'])
	#             # core.wait(0.5)
	__end__
	set _prepare ""

define inline_script utils
	set description "Executes Python code"
	set _run ""
	___prepare__
	import numpy as np
	import os, sys
	import os.path as op
	import math
	import random
	import pandas as pd
	import yaml
	import pylink
	
	from psychopy import visual, tools, colors, event
	import psychopy.tools.colorspacetools as ct
	from psychopy.tools.monitorunittools import deg2pix, pix2deg
	import itertools
	from typing import Optional
	
	import time
	import colorsys
	
	
	def wait_for_saccade_end_timeout(timeout=None):
	    """endtime, startpos, endpos"""
	    t0 = clock.time()
	    tc = timeout
	    for ms in clock.loop_for(timeout):
	        d = pylink.getEYELINK().getNextData()
	        if d == pylink.ENDSACC:
	            float_data  = pylink.getEYELINK().getFloatData()
	            tc = float_data.getTime() - eyetracker._get_eyelink_clock_async()
	            if tc > t0:
	                break
	                
	    if tc == timeout:
	        return -1, None, None
	    
	    return tc, float_data.getStartGaze(), float_data.getEndGaze()
	
	# TODO: This should return two sizes, one for vert, one for hori
	def dva_per_pix(height_cm=30, distance_cm=70, vert_res_pix=1080):
	    """ calculate degrees of visual angle per pixel,
	    to use for screen boundaries when plotting/masking
	    Parameters
	    ----------
	    height_cm : int
	        screen height
	    distance_cm: float
	        screen distance (same unit as height)
	    vert_res_pix : int
	        vertical resolution of screen
	    
	    Outputs
	    -------
	    deg_per_px : float
	        degree (dva) per pixel
	    
	    """
	
	    # screen size in degrees / vertical resolution
	    deg_per_px = (2.0 * np.degrees(np.arctan(height_cm / (2.0 * distance_cm)))) / vert_res_pix
	
	    return deg_per_px
	
	
	def circle_points(radius, n_points):
	    """ define positions in circle
	
	    Parameters
	    ----------
	    radius : list/arr
	        list of radius
	    n_points: list/arr
	        number of points per radius
	    
	    Outputs
	    -------
	    circles : list
	        list of [x,y] positions per radius
	    
	    """
	    circles = []
	
	    for r, n in zip(radius, n_points):
	        t = np.arange(0, 2 * np.pi, 2 * np.pi / float(n))  # np.linspace(0, 2 * np.pi, n)
	        x = r * np.cos(t)
	        y = r * np.sin(t)
	        circles.append(np.c_[x, y])
	
	    return circles
	
	
	def grid_coordinates(x_count: int, y_count: int, pixel_spacing: float):
	    """
	    Given the number of x, and y points and the desired spacing in degrees, return a list of pixel coordiantes
	    representing a rectangular grid
	    Parameters
	    ----------
	    x_count
	    y_count
	    pixel_spacing
	
	    Returns
	    -------
	
	    """
	    half_x = x_count // 2
	    half_y = y_count // 2
	
	    x_range = np.arange(-pixel_spacing * half_x, pixel_spacing * (1 + half_x), pixel_spacing, dtype=np.int32)
	    y_range = np.arange(-pixel_spacing * half_y, pixel_spacing * (1 + half_y), pixel_spacing, dtype=np.int32)
	    X, Y = np.meshgrid(x_range, y_range)
	    return list(zip(X.ravel(), Y.ravel()))
	
	
	def construct_singleton_pairs(pixel_spacing: float, x_count, y_count):
	    """
	    Should return every possible combination of target, distractor pairs which are the center of each quadrant
	    I.e., the center of each half diagonal
	    Returns
	    -------
	
	    """
	    # Calculate the indices of the elements on the diagonals that are at the center of their respective quadrants
	    half_x = x_count // 2
	    half_y = y_count // 2
	
	    x_range = np.arange(-pixel_spacing * half_x, pixel_spacing * (1 + half_x), pixel_spacing, dtype=np.int32)
	    y_range = np.arange(-pixel_spacing * half_y, pixel_spacing * (1 + half_y), pixel_spacing, dtype=np.int32)
	
	    small_x = x_range[half_x//2]
	    big_x = x_range[half_x+(half_x//2)+1]
	    small_y = y_range[half_y//2]
	    big_y = y_range[half_y+(half_y//2)+1]
	    indices = []
	    indices.append((int(small_x), int(small_y)))  # top_left
	    indices.append((int(small_x), int(big_y)))  # top_right
	    indices.append((int(big_x), int(small_y)))  # bottom_left
	    indices.append((int(big_x), int(big_y)) ) # bottom_right
	
	    # Return all possible combinations where target location != distractor location
	    coords = [(indices1, indices2) for indices1 in indices for indices2 in indices if indices1 != indices2]
	    # print(coords[0])
	    # return [coords[0]]
	    return coords
	
	
	def get_grid_array(positions, ecc_range, convert2pix=True, screen=[1920, 1080],
	                   height_cm=30, distance_cm=70,
	                   constraint_type='ellipse', constraint_bounds_pix=[500, 700]):
	    """ get position array
	    needs postion list with positions per ecc
	    and ecc range
	
	    Parameters
	    ----------
	    positions : list/arr
	        list of [x,y] positions per ecc
	    ecc_range: list/arr
	        list with eccs in position
	    convert2pix: bool
	        if outputted list in pixels or not
	    constrain_type: str
	        type of position contraint to use eg: 'ellipse', 'square', 'rectangle'
	    constraint_bounds_pix: list/arr
	        bounds to constraint positions to
	    
	    Outputs
	    -------
	    pos_list : arr
	        list of [x,y] positions (pix if convert2pix == True)
	    ecc_list: arr
	        list of ecc per position pair (dva)
	    
	    """
	
	    pos_list = []
	    ecc_list = []
	
	    # if converting to pix, then need to convert the bounds to deg
	    if convert2pix:
	        constraint_bounds = constraint_bounds_pix * dva_per_pix(height_cm=height_cm,
	                                                                distance_cm=distance_cm,
	                                                                vert_res_pix=screen[-1])
	    else:
	        constraint_bounds = constraint_bounds_pix
	
	    for ind, e in enumerate(positions):
	
	        # append list of positions
	        for pos in e:
	            # check if within bounds
	            if constraint_type == 'ellipse' and \
	                    (((pos[0] ** 2) / (max(constraint_bounds) ** 2) + (pos[1] ** 2) / (
	                            min(constraint_bounds) ** 2)) <= 1):
	                pos_list.append(list(pos))
	
	                # append eccentricity of these positions
	                ecc_list.append(ecc_range[ind])
	
	    if convert2pix:
	        pos_list = pos_list / dva_per_pix(height_cm=height_cm,
	                                          distance_cm=distance_cm,
	                                          vert_res_pix=screen[-1])
	    else:
	        pos_list = np.array(pos_list)
	
	    return pos_list, np.array(ecc_list)
	
	
	def draw_instructions(win, instructions, keys=['b'], visual_obj=[], image_path=[],
	                      color=(1, 1, 1), font='Helvetica Neue', pos=(0, 0), height=30,  # .65,
	                      italic=True, anchorHoriz='center', anchorVert='center'):
	    """ draw instructions on screen
	    
	    Parameters
	    ----------
	    win : object
	        window object to draw on
	    instructions : str
	        instruction string to draw 
	    key: list
	        list of keys to skip instructions
	    visual_obj: list
	        if not empty, should have psychopy visual objects (to add to the display ex: side rectangles to limit display)
	        
	    """
	
	    text = visual.TextStim(win=win,
	                           text=instructions,
	                           color=color,
	                           # font=font,
	                           pos=pos,
	                           height=height,
	                           italic=italic,
	                           anchorHoriz=anchorHoriz,
	                           anchorVert=anchorVert
	                           )
	
	    # draw text 
	    text.draw()
	
	    if len(visual_obj) > 0:
	        for w in range(len(visual_obj)):
	            visual_obj[w].draw()
	
	    if len(image_path) > 0:
	        for _, img in enumerate(image_path):
	            img_stim = visual.ImageStim(win=win,
	                                        image=img,
	                                        pos=(0, 100))
	            img_stim.draw()
	
	    win.flip()
	
	    key_pressed = event.waitKeys(keyList=keys)
	
	    return key_pressed
	
	def get_curr_sample(screen_dims):
	    curPos = eyetracker.sample()	
	    # print("CUR_SAMP", curPos)
	    # print("SCREEN_DIMS", screen_dims)
	    x_sample = curPos[0] - screen_dims[0]/2
	    y_sample = -(curPos[1] - screen_dims[1]/2)
	    return (x_sample, y_sample)
	    
	def distance(p1, p2, deg=False, win=None):
	    dist = np.sqrt((p1[0] - p2[0])**2 + (p1[1] - p2[1])**2)
	    if deg:
	        if win is None:
	            raise ValueError
	        return pix2deg(dist, win.monitor)
	    else:
	        return dist
	__end__

